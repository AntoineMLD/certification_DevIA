import os
import sqlite3
import requests
from PIL import Image
from io import BytesIO
import hashlib
from bs4 import BeautifulSoup
import time
from pathlib import Path

class OpticalPipeline:
    """
    Pipeline pour traiter et sauvegarder les donn√©es des verres optiques.
    
    Cette classe g√®re le stockage des donn√©es dans SQLite.
    Les images seront t√©l√©charg√©es s√©par√©ment par le script download_images.py
    """
    
    # Configuration de la base de donn√©es
    TABLE_NAME = "staging"
    DB_FOLDER = Path("..") / ".." / ".." / "Base_de_donnees"
    DB_NAME = "france_optique.db"
    
    def __init__(self):
        """Initialise le pipeline avec les configurations de base."""
        # S'assure que le dossier de la base de donn√©es existe
        self.DB_FOLDER.mkdir(parents=True, exist_ok=True)
        self.DB_PATH = str(self.DB_FOLDER / self.DB_NAME)
        self.create_database_table()

    def create_database_table(self):
        """Cr√©e la table staging si elle n'existe pas."""
        query = """
        CREATE TABLE IF NOT EXISTS staging (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            glass_name TEXT,             -- Nom du verre
            range TEXT,                  -- Gamme
            series TEXT,                 -- S√©rie
            variant TEXT,                -- Variante
            height TEXT,                 -- Hauteur
            protection_treatment TEXT,    -- Traitement de protection
            photochromic_treatment TEXT, -- Traitement photochromique
            material TEXT,               -- Mat√©riau
            glass_index TEXT,            -- Indice de r√©fraction
            supplier TEXT,               -- Fournisseur
            engraving_url TEXT,          -- URL de la gravure
            source_url TEXT,             -- URL source
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
        """
        try:
            with sqlite3.connect(self.DB_PATH) as connection:
                cursor = connection.cursor()
                cursor.execute(query)
                connection.commit()
                
        except sqlite3.Error as error:
            print(f"‚ùå Erreur cr√©ation table: {error}")
            raise

    def get_image_url(self, html_content):
        """
        Extrait l'URL de l'image depuis le HTML.
        
        Args:
            html_content (str): Code HTML contenant l'image
            
        Returns:
            str ou None: URL de l'image si trouv√©e
        """
        if not html_content or not isinstance(html_content, str):
            return None

        try:
            # Cas 1: C'est d√©j√† une URL
            if html_content.startswith(('http://', 'https://')):
                return html_content

            # Cas 2: C'est du HTML
            soup = BeautifulSoup(html_content, 'html.parser')
            img_tag = soup.find('img')
            
            if not img_tag or not img_tag.get('src'):
                return None
                
            # R√©cup√®re et nettoie l'URL
            url = img_tag['src']
            
            # Ajoute le protocole si n√©cessaire
            if url.startswith('//'):
                return 'https:' + url
            elif not url.startswith(('http://', 'https://')):
                return 'https://' + url.lstrip('/')
                
            return url

        except Exception:
            return None

    def save_to_database(self, item, spider):
        """Sauvegarde les donn√©es dans la base."""
        try:
            # Connexion √† la base de donn√©es
            with sqlite3.connect(self.DB_PATH) as connection:
                cursor = connection.cursor()
                
                # Pr√©paration de la requ√™te d'insertion
                # On utilise glass_index au lieu de index (mot r√©serv√© SQL)
                query = f"""
                    INSERT INTO {self.TABLE_NAME} (
                        glass_name, material, glass_index,
                        supplier, engraving_url, source_url
                    ) VALUES (?, ?, ?, ?, ?, ?)
                """
                
                # Valeurs √† ins√©rer
                values = (
                    item.get('glass_name'),
                    item.get('material'),
                    item.get('glass_index'),
                    item.get('supplier'),
                    item.get('engraving_url'),
                    item.get('source_url')
                )
                
                # Ex√©cution de la requ√™te
                cursor.execute(query, values)
                connection.commit()
                
            spider.logger.info(f"‚úÖ Donn√©es sauvegard√©es: {item['source_url']}")
            return True
            
        except sqlite3.Error as error:
            spider.logger.error(f"‚ùå Erreur base de donn√©es: {error}")
            return False

    def process_item(self, item, spider):
        """
        Traite un nouvel item du spider.
        
        Cette m√©thode est appel√©e automatiquement par Scrapy pour chaque item trouv√©.
        Elle extrait l'URL de l'image si pr√©sente et sauvegarde les donn√©es.
        
        Args:
            item (dict): Item √† traiter
            spider: Spider Scrapy qui a trouv√© l'item
            
        Returns:
            dict: Item trait√©
        """
        try:
            # 1. Extrait l'URL de l'image si pr√©sente
            if item.get('engraving_url'):
                item['engraving_url'] = self.get_image_url(item['engraving_url'])

            # 2. Sauvegarde en base de donn√©es
            self.save_to_database(item, spider)
            return item

        except Exception as error:
            spider.logger.error(f"‚ùå Erreur traitement item: {error}")
            return item

    def open_spider(self, spider):
        """Appel√© quand le spider d√©marre."""
        spider.logger.info("üöÄ D√©marrage du pipeline")

    def close_spider(self, spider):
        """Appel√© quand le spider termine."""
        spider.logger.info("‚úÖ Pipeline termin√©")
